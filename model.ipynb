{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30317,"status":"ok","timestamp":1664185212143,"user":{"displayName":"Nya Fredy Yann NDINGUE","userId":"12675892843960354959"},"user_tz":-120},"id":"TcBGqIEo4qDX","outputId":"d5b1f9ab-8f70-4d9c-9568-62b3594ab4ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# here we link our notebook to our gdrive space\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3284,"status":"ok","timestamp":1664185229566,"user":{"displayName":"Nya Fredy Yann NDINGUE","userId":"12675892843960354959"},"user_tz":-120},"id":"pp5KWfTIXwxB","outputId":"b8191dc8-8292-4a25-97a4-c0fda9920b0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting category_encoders\n","  Downloading category_encoders-2.5.0-py2.py3-none-any.whl (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.7.3)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.21.6)\n","Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.3.5)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.12.2)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.0.2)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.2)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->category_encoders) (2022.2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n","Installing collected packages: category-encoders\n","Successfully installed category-encoders-2.5.0\n"]}],"source":["!pip install category_encoders"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":72405,"status":"ok","timestamp":1664185307929,"user":{"displayName":"Nya Fredy Yann NDINGUE","userId":"12675892843960354959"},"user_tz":-120},"id":"amqpmBHNYcPn","outputId":"cc438207-a9d2-47b4-9f89-a9edc181a053"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pycountry-convert\n","  Downloading pycountry_convert-0.7.2-py3-none-any.whl (13 kB)\n","Collecting repoze.lru>=0.7\n","  Downloading repoze.lru-0.7-py3-none-any.whl (10 kB)\n","Collecting pytest-cov>=2.5.1\n","  Downloading pytest_cov-3.0.0-py3-none-any.whl (20 kB)\n","Collecting pycountry>=16.11.27.1\n","  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 45.0 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pytest>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from pycountry-convert) (3.6.4)\n","Requirement already satisfied: wheel>=0.30.0 in /usr/local/lib/python3.7/dist-packages (from pycountry-convert) (0.37.1)\n","Collecting pprintpp>=0.3.0\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Collecting pytest-mock>=1.6.3\n","  Downloading pytest_mock-3.8.2-py3-none-any.whl (9.1 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pycountry>=16.11.27.1->pycountry-convert) (57.4.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.4.0->pycountry-convert) (22.1.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.4.0->pycountry-convert) (8.14.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.4.0->pycountry-convert) (1.11.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.4.0->pycountry-convert) (0.7.1)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.4.0->pycountry-convert) (1.4.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.4.0->pycountry-convert) (1.15.0)\n","Collecting pytest>=3.4.0\n","  Downloading pytest-7.1.3-py3-none-any.whl (298 kB)\n","\u001b[K     |████████████████████████████████| 298 kB 39.3 MB/s \n","\u001b[?25hCollecting coverage[toml]>=5.2.1\n","  Downloading coverage-6.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209 kB)\n","\u001b[K     |████████████████████████████████| 209 kB 67.7 MB/s \n","\u001b[?25hRequirement already satisfied: tomli in /usr/local/lib/python3.7/dist-packages (from coverage[toml]>=5.2.1->pytest-cov>=2.5.1->pycountry-convert) (2.0.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest>=3.4.0->pycountry-convert) (21.3)\n","Collecting iniconfig\n","  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n","Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.4.0->pycountry-convert) (4.12.0)\n","Collecting pytest>=3.4.0\n","  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n","\u001b[K     |████████████████████████████████| 297 kB 67.0 MB/s \n","\u001b[?25h  Downloading pytest-7.1.1-py3-none-any.whl (297 kB)\n","\u001b[K     |████████████████████████████████| 297 kB 65.2 MB/s \n","\u001b[?25h  Downloading pytest-7.1.0-py3-none-any.whl (297 kB)\n","\u001b[K     |████████████████████████████████| 297 kB 78.5 MB/s \n","\u001b[?25h  Downloading pytest-7.0.1-py3-none-any.whl (296 kB)\n","\u001b[K     |████████████████████████████████| 296 kB 63.7 MB/s \n","\u001b[?25h  Downloading pytest-7.0.0-py3-none-any.whl (296 kB)\n","\u001b[K     |████████████████████████████████| 296 kB 62.7 MB/s \n","\u001b[?25h  Downloading pytest-6.2.5-py3-none-any.whl (280 kB)\n","\u001b[K     |████████████████████████████████| 280 kB 63.7 MB/s \n","\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pytest>=3.4.0->pycountry-convert) (0.10.2)\n","  Downloading pytest-6.2.4-py3-none-any.whl (280 kB)\n","\u001b[K     |████████████████████████████████| 280 kB 48.7 MB/s \n","\u001b[?25h  Downloading pytest-6.2.3-py3-none-any.whl (280 kB)\n","\u001b[K     |████████████████████████████████| 280 kB 65.4 MB/s \n","\u001b[?25h  Downloading pytest-6.2.2-py3-none-any.whl (280 kB)\n","\u001b[K     |████████████████████████████████| 280 kB 59.3 MB/s \n","\u001b[?25h  Downloading pytest-6.2.1-py3-none-any.whl (279 kB)\n","\u001b[K     |████████████████████████████████| 279 kB 71.7 MB/s \n","\u001b[?25h  Downloading pytest-6.2.0-py3-none-any.whl (279 kB)\n","\u001b[K     |████████████████████████████████| 279 kB 76.0 MB/s \n","\u001b[?25h  Downloading pytest-6.1.2-py3-none-any.whl (272 kB)\n","\u001b[K     |████████████████████████████████| 272 kB 64.6 MB/s \n","\u001b[?25h  Downloading pytest-6.1.1-py3-none-any.whl (272 kB)\n","\u001b[K     |████████████████████████████████| 272 kB 78.0 MB/s \n","\u001b[?25h  Downloading pytest-6.1.0-py3-none-any.whl (272 kB)\n","\u001b[K     |████████████████████████████████| 272 kB 22.2 MB/s \n","\u001b[?25h  Downloading pytest-6.0.2-py3-none-any.whl (270 kB)\n","\u001b[K     |████████████████████████████████| 270 kB 74.8 MB/s \n","\u001b[?25h  Downloading pytest-6.0.1-py3-none-any.whl (270 kB)\n","\u001b[K     |████████████████████████████████| 270 kB 69.2 MB/s \n","\u001b[?25h  Downloading pytest-6.0.0-py3-none-any.whl (270 kB)\n","\u001b[K     |████████████████████████████████| 270 kB 76.7 MB/s \n","\u001b[?25h  Downloading pytest-5.4.3-py3-none-any.whl (248 kB)\n","\u001b[K     |████████████████████████████████| 248 kB 71.2 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest>=3.4.0->pycountry-convert) (0.2.5)\n","  Downloading pytest-5.4.2-py3-none-any.whl (247 kB)\n","\u001b[K     |████████████████████████████████| 247 kB 76.5 MB/s \n","\u001b[?25h  Downloading pytest-5.4.1-py3-none-any.whl (246 kB)\n","\u001b[K     |████████████████████████████████| 246 kB 75.6 MB/s \n","\u001b[?25h  Downloading pytest-5.4.0-py3-none-any.whl (247 kB)\n","\u001b[K     |████████████████████████████████| 247 kB 67.0 MB/s \n","\u001b[?25h  Downloading pytest-5.3.5-py3-none-any.whl (235 kB)\n","\u001b[K     |████████████████████████████████| 235 kB 74.0 MB/s \n","\u001b[?25h  Downloading pytest-5.3.4-py3-none-any.whl (235 kB)\n","\u001b[K     |████████████████████████████████| 235 kB 74.3 MB/s \n","\u001b[?25h  Downloading pytest-5.3.3-py3-none-any.whl (235 kB)\n","\u001b[K     |████████████████████████████████| 235 kB 69.9 MB/s \n","\u001b[?25h  Downloading pytest-5.3.2-py3-none-any.whl (234 kB)\n","\u001b[K     |████████████████████████████████| 234 kB 80.0 MB/s \n","\u001b[?25h  Downloading pytest-5.3.1-py3-none-any.whl (233 kB)\n","\u001b[K     |████████████████████████████████| 233 kB 68.1 MB/s \n","\u001b[?25h  Downloading pytest-5.3.0-py3-none-any.whl (233 kB)\n","\u001b[K     |████████████████████████████████| 233 kB 83.3 MB/s \n","\u001b[?25h  Downloading pytest-5.2.4-py3-none-any.whl (227 kB)\n","\u001b[K     |████████████████████████████████| 227 kB 79.8 MB/s \n","\u001b[?25h  Downloading pytest-5.2.3-py3-none-any.whl (227 kB)\n","\u001b[K     |████████████████████████████████| 227 kB 84.7 MB/s \n","\u001b[?25h  Downloading pytest-5.2.2-py3-none-any.whl (227 kB)\n","\u001b[K     |████████████████████████████████| 227 kB 83.0 MB/s \n","\u001b[?25h  Downloading pytest-5.2.1-py3-none-any.whl (226 kB)\n","\u001b[K     |████████████████████████████████| 226 kB 109.1 MB/s \n","\u001b[?25h  Downloading pytest-5.2.0-py3-none-any.whl (226 kB)\n","\u001b[K     |████████████████████████████████| 226 kB 104.9 MB/s \n","\u001b[?25h  Downloading pytest-5.1.3-py3-none-any.whl (224 kB)\n","\u001b[K     |████████████████████████████████| 224 kB 107.1 MB/s \n","\u001b[?25h  Downloading pytest-5.1.2-py3-none-any.whl (224 kB)\n","\u001b[K     |████████████████████████████████| 224 kB 106.5 MB/s \n","\u001b[?25h  Downloading pytest-5.1.1-py3-none-any.whl (223 kB)\n","\u001b[K     |████████████████████████████████| 223 kB 110.3 MB/s \n","\u001b[?25h  Downloading pytest-5.1.0-py3-none-any.whl (223 kB)\n","\u001b[K     |████████████████████████████████| 223 kB 84.8 MB/s \n","\u001b[?25h  Downloading pytest-5.0.1-py3-none-any.whl (221 kB)\n","\u001b[K     |████████████████████████████████| 221 kB 82.3 MB/s \n","\u001b[?25h  Downloading pytest-5.0.0-py3-none-any.whl (221 kB)\n","\u001b[K     |████████████████████████████████| 221 kB 82.7 MB/s \n","\u001b[?25h  Downloading pytest-4.6.11-py2.py3-none-any.whl (231 kB)\n","\u001b[K     |████████████████████████████████| 231 kB 108.6 MB/s \n","\u001b[?25h  Downloading pytest-4.6.10-py2.py3-none-any.whl (231 kB)\n","\u001b[K     |████████████████████████████████| 231 kB 86.9 MB/s \n","\u001b[?25h  Downloading pytest-4.6.9-py2.py3-none-any.whl (231 kB)\n","\u001b[K     |████████████████████████████████| 231 kB 87.0 MB/s \n","\u001b[?25h  Downloading pytest-4.6.8-py2.py3-none-any.whl (230 kB)\n","\u001b[K     |████████████████████████████████| 230 kB 83.1 MB/s \n","\u001b[?25h  Downloading pytest-4.6.7-py2.py3-none-any.whl (230 kB)\n","\u001b[K     |████████████████████████████████| 230 kB 84.2 MB/s \n","\u001b[?25h  Downloading pytest-4.6.6-py2.py3-none-any.whl (230 kB)\n","\u001b[K     |████████████████████████████████| 230 kB 84.0 MB/s \n","\u001b[?25h  Downloading pytest-4.6.5-py2.py3-none-any.whl (230 kB)\n","\u001b[K     |████████████████████████████████| 230 kB 87.9 MB/s \n","\u001b[?25h  Downloading pytest-4.6.4-py2.py3-none-any.whl (229 kB)\n","\u001b[K     |████████████████████████████████| 229 kB 86.2 MB/s \n","\u001b[?25h  Downloading pytest-4.6.3-py2.py3-none-any.whl (229 kB)\n","\u001b[K     |████████████████████████████████| 229 kB 85.4 MB/s \n","\u001b[?25h  Downloading pytest-4.6.2-py2.py3-none-any.whl (229 kB)\n","\u001b[K     |████████████████████████████████| 229 kB 85.4 MB/s \n","\u001b[?25h  Downloading pytest-4.6.1-py2.py3-none-any.whl (229 kB)\n","\u001b[K     |████████████████████████████████| 229 kB 111.7 MB/s \n","\u001b[?25h  Downloading pytest-4.6.0-py2.py3-none-any.whl (229 kB)\n","\u001b[K     |████████████████████████████████| 229 kB 60.9 MB/s \n","\u001b[?25hINFO: pip is looking at multiple versions of coverage to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of coverage[toml] to determine which version is compatible with other requirements. This could take a while.\n","Collecting coverage[toml]>=5.2.1\n","  Downloading coverage-6.4.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209 kB)\n","\u001b[K     |████████████████████████████████| 209 kB 113.4 MB/s \n","\u001b[?25h  Downloading coverage-6.4.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209 kB)\n","\u001b[K     |████████████████████████████████| 209 kB 107.8 MB/s \n","\u001b[?25h  Downloading coverage-6.4.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n","\u001b[K     |████████████████████████████████| 208 kB 81.8 MB/s \n","\u001b[?25h  Downloading coverage-6.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n","\u001b[K     |████████████████████████████████| 208 kB 80.4 MB/s \n","\u001b[?25h  Downloading coverage-6.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n","\u001b[K     |████████████████████████████████| 207 kB 79.9 MB/s \n","\u001b[?25h  Downloading coverage-6.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n","\u001b[K     |████████████████████████████████| 207 kB 81.4 MB/s \n","\u001b[?25h  Downloading coverage-6.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n","\u001b[K     |████████████████████████████████| 207 kB 99.8 MB/s \n","\u001b[?25hINFO: pip is looking at multiple versions of coverage to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of coverage[toml] to determine which version is compatible with other requirements. This could take a while.\n","  Downloading coverage-6.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n","\u001b[K     |████████████████████████████████| 207 kB 98.8 MB/s \n","\u001b[?25h  Downloading coverage-6.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (213 kB)\n","\u001b[K     |████████████████████████████████| 213 kB 109.3 MB/s \n","\u001b[?25h  Downloading coverage-6.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (213 kB)\n","\u001b[K     |████████████████████████████████| 213 kB 104.1 MB/s \n","\u001b[?25h  Downloading coverage-6.1.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (213 kB)\n","\u001b[K     |████████████████████████████████| 213 kB 102.5 MB/s \n","\u001b[?25h  Downloading coverage-6.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (213 kB)\n","\u001b[K     |████████████████████████████████| 213 kB 89.5 MB/s \n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n","  Downloading coverage-6.0.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (253 kB)\n","\u001b[K     |████████████████████████████████| 253 kB 79.6 MB/s \n","\u001b[?25h  Downloading coverage-6.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (252 kB)\n","\u001b[K     |████████████████████████████████| 252 kB 76.9 MB/s \n","\u001b[?25h  Downloading coverage-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (252 kB)\n","\u001b[K     |████████████████████████████████| 252 kB 82.9 MB/s \n","\u001b[?25h  Downloading coverage-5.5-cp37-cp37m-manylinux2010_x86_64.whl (242 kB)\n","\u001b[K     |████████████████████████████████| 242 kB 80.8 MB/s \n","\u001b[?25h  Downloading coverage-5.4-cp37-cp37m-manylinux2010_x86_64.whl (242 kB)\n","\u001b[K     |████████████████████████████████| 242 kB 84.1 MB/s \n","\u001b[?25h  Downloading coverage-5.3.1-cp37-cp37m-manylinux2010_x86_64.whl (242 kB)\n","\u001b[K     |████████████████████████████████| 242 kB 80.2 MB/s \n","\u001b[?25h  Downloading coverage-5.3-cp37-cp37m-manylinux1_x86_64.whl (229 kB)\n","\u001b[K     |████████████████████████████████| 229 kB 104.8 MB/s \n","\u001b[?25h  Downloading coverage-5.2.1-cp37-cp37m-manylinux1_x86_64.whl (229 kB)\n","\u001b[K     |████████████████████████████████| 229 kB 78.4 MB/s \n","\u001b[?25hINFO: pip is looking at multiple versions of pytest-cov to determine which version is compatible with other requirements. This could take a while.\n","Collecting pytest-cov>=2.5.1\n","  Downloading pytest_cov-2.12.1-py2.py3-none-any.whl (20 kB)\n","  Downloading pytest_cov-2.12.0-py2.py3-none-any.whl (20 kB)\n","  Downloading pytest_cov-2.11.1-py2.py3-none-any.whl (20 kB)\n","  Downloading pytest_cov-2.11.0-py2.py3-none-any.whl (20 kB)\n","  Downloading pytest_cov-2.10.1-py2.py3-none-any.whl (19 kB)\n","Collecting coverage>=4.4\n","  Downloading coverage-5.2-cp37-cp37m-manylinux1_x86_64.whl (229 kB)\n","\u001b[K     |████████████████████████████████| 229 kB 67.1 MB/s \n","\u001b[?25h  Downloading coverage-5.1-cp37-cp37m-manylinux1_x86_64.whl (227 kB)\n","\u001b[K     |████████████████████████████████| 227 kB 81.4 MB/s \n","\u001b[?25h  Downloading coverage-5.0.4-cp37-cp37m-manylinux1_x86_64.whl (227 kB)\n","\u001b[K     |████████████████████████████████| 227 kB 75.5 MB/s \n","\u001b[?25h  Downloading coverage-5.0.3-cp37-cp37m-manylinux1_x86_64.whl (227 kB)\n","\u001b[K     |████████████████████████████████| 227 kB 55.6 MB/s \n","\u001b[?25h  Downloading coverage-5.0.2-cp37-cp37m-manylinux1_x86_64.whl (226 kB)\n","\u001b[K     |████████████████████████████████| 226 kB 76.6 MB/s \n","\u001b[?25h  Downloading coverage-5.0.1-cp37-cp37m-manylinux1_x86_64.whl (226 kB)\n","\u001b[K     |████████████████████████████████| 226 kB 78.4 MB/s \n","\u001b[?25h  Downloading coverage-5.0-cp37-cp37m-manylinux1_x86_64.whl (226 kB)\n","\u001b[K     |████████████████████████████████| 226 kB 109.4 MB/s \n","\u001b[?25h  Downloading coverage-4.5.4-cp37-cp37m-manylinux1_x86_64.whl (205 kB)\n","\u001b[K     |████████████████████████████████| 205 kB 92.7 MB/s \n","\u001b[?25h  Downloading coverage-4.5.3-cp37-cp37m-manylinux1_x86_64.whl (204 kB)\n","\u001b[K     |████████████████████████████████| 204 kB 94.1 MB/s \n","\u001b[?25h  Downloading coverage-4.5.2-cp37-cp37m-manylinux1_x86_64.whl (205 kB)\n","\u001b[K     |████████████████████████████████| 205 kB 101.1 MB/s \n","\u001b[?25h  Downloading coverage-4.5.1-cp37-cp37m-manylinux1_x86_64.whl (202 kB)\n","\u001b[K     |████████████████████████████████| 202 kB 79.2 MB/s \n","\u001b[?25h  Downloading coverage-4.5.tar.gz (378 kB)\n","\u001b[K     |████████████████████████████████| 378 kB 74.5 MB/s \n","\u001b[?25h  Downloading coverage-4.4.2.tar.gz (374 kB)\n","\u001b[K     |████████████████████████████████| 374 kB 76.1 MB/s \n","\u001b[?25h  Downloading coverage-4.4.1.tar.gz (369 kB)\n","\u001b[K     |████████████████████████████████| 369 kB 72.7 MB/s \n","\u001b[?25h  Downloading coverage-4.4.tar.gz (369 kB)\n","\u001b[K     |████████████████████████████████| 369 kB 87.6 MB/s \n","\u001b[?25hCollecting pytest-cov>=2.5.1\n","  Downloading pytest_cov-2.10.0-py2.py3-none-any.whl (19 kB)\n","  Downloading pytest_cov-2.9.0-py2.py3-none-any.whl (19 kB)\n","INFO: pip is looking at multiple versions of pytest-mock to determine which version is compatible with other requirements. This could take a while.\n","Collecting pytest-mock>=1.6.3\n","  Downloading pytest_mock-3.8.1-py3-none-any.whl (9.1 kB)\n","  Downloading pytest_mock-3.8.0-py3-none-any.whl (9.1 kB)\n","  Downloading pytest_mock-3.7.0-py3-none-any.whl (12 kB)\n","  Downloading pytest_mock-3.6.1-py3-none-any.whl (12 kB)\n","  Downloading pytest_mock-3.6.0-py3-none-any.whl (12 kB)\n","  Downloading pytest_mock-3.5.1-py3-none-any.whl (12 kB)\n","  Downloading pytest_mock-3.5.0-py3-none-any.whl (12 kB)\n","INFO: pip is looking at multiple versions of pytest-mock to determine which version is compatible with other requirements. This could take a while.\n","  Downloading pytest_mock-3.4.0-py3-none-any.whl (11 kB)\n","  Downloading pytest_mock-3.3.1-py3-none-any.whl (11 kB)\n","  Downloading pytest_mock-3.3.0-py3-none-any.whl (11 kB)\n","  Downloading pytest_mock-3.2.0-py3-none-any.whl (10 kB)\n","Building wheels for collected packages: pycountry\n","  Building wheel for pycountry (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681845 sha256=dd4a8bfe534d10c0869314f0e7fe7925d113cf9f0e47d6406aa0dc60d8dd8742\n","  Stored in directory: /root/.cache/pip/wheels/0e/06/e8/7ee176e95ea9a8a8c3b3afcb1869f20adbd42413d4611c6eb4\n","Successfully built pycountry\n","Installing collected packages: coverage, repoze.lru, pytest-mock, pytest-cov, pycountry, pprintpp, pycountry-convert\n","Successfully installed coverage-6.4.4 pprintpp-0.4.0 pycountry-22.3.5 pycountry-convert-0.7.2 pytest-cov-2.9.0 pytest-mock-3.2.0 repoze.lru-0.7\n"]}],"source":["!pip install pycountry-convert"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4768,"status":"ok","timestamp":1664185326612,"user":{"displayName":"Nya Fredy Yann NDINGUE","userId":"12675892843960354959"},"user_tz":-120},"id":"k2gMBUp74wn-"},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","from category_encoders import TargetEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OrdinalEncoder\n","from category_encoders import LeaveOneOutEncoder\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import os\n","import pycountry_convert as pc\n","import sklearn\n","import pandas as pd\n","import numpy as np\n","import json\n","import random, string\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","from sklearn.preprocessing import StandardScaler\n","import xgboost as xgb\n","from xgboost import XGBRegressor\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import RepeatedKFold\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import log_loss\n","from sklearn.model_selection import train_test_split\n","import category_encoders as ce\n","%matplotlib inline"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1894,"status":"ok","timestamp":1664185332738,"user":{"displayName":"Nya Fredy Yann NDINGUE","userId":"12675892843960354959"},"user_tz":-120},"id":"5y09CDqm593P"},"outputs":[],"source":["# load files\n","train = pd.read_csv('/content/drive/MyDrive/Zindi/ai4d-lab-tanzania-tourism-classification-challenge/Train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/Zindi/ai4d-lab-tanzania-tourism-classification-challenge/Test.csv')\n","variableDefinitions = pd.read_csv('/content/drive/MyDrive/Zindi/ai4d-lab-tanzania-tourism-classification-challenge/VariableDefinitions.csv')\n","sampleSubmission = pd.read_csv('/content/drive/MyDrive/Zindi/ai4d-lab-tanzania-tourism-classification-challenge/SampleSubmission.csv')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"UYQeQdCdX_-b","executionInfo":{"status":"ok","timestamp":1664185336760,"user_tz":-120,"elapsed":473,"user":{"displayName":"Nya Fredy Yann NDINGUE","userId":"12675892843960354959"}}},"outputs":[],"source":["# data preprocessing\n","# Feature Engineering\n","\n","# to map country to continent\n","def country_to_continent(df):\n","  df = df.replace('SWIZERLAND', 'SWITZERLAND')\n","  df = df.replace('MORROCO', 'MOROCCO')\n","  df = df.replace('UAE', 'UNITED ARAB EMIRATES')\n","  df = df.replace('KOREA', 'SOUTH KOREA')\n","  df = df.replace('DRC', 'DEMOCRATIC REPUBLIC OF THE CONGO')\n","  df = df.replace('MALT', 'MALTA')\n","  df = df.replace('COSTARICA', 'COSTA RICA')\n","  df = df.replace('COMORO', 'COMOROS')\n","  df = df.replace('SAUD ARABIA', 'SAUDI ARABIA')\n","  df = df.replace('PHILIPINES', 'PHILIPPINES')\n","  df = df.replace('SCOTLAND', 'UNITED KINGDOM')\n","  df = df.replace('UKRAIN', 'UKRAINE')\n","  df = df.replace('SOMALI', 'SOMALIA')\n","  df = df.replace('ECUADO', 'ECUADOR')\n","  df = df.replace('MONECASQUE', 'MONACO')\n","  df = df.replace('TRINIDAD TOBACCO', 'TRINIDAD AND TOBAGO')\n","  df = df.replace('BURGARIA', 'BULGARIA')\n","  df = df.replace('BOSNIA', 'BOSNIA AND HERZEGOVINA')\n","  df = df.replace('DJIBOUT', 'DJIBOUTI')\n","  df['continent'] = df.apply(lambda x: pc.country_alpha2_to_continent_code(pc.country_name_to_country_alpha2(x['country'], cn_name_format=\"upper\")), axis = 1)\n","  return df\n","\n","# to rebinning age_group\n","def binning_age_group(df, bins=3):\n","  # to 3 bins : -24, 25-44, 45+\n","  def bin3(age_group):\n","    if(age_group=='18-24' or age_group=='<18'):\n","      return '-24'\n","    if(age_group=='25-44'):\n","      return '25-44'\n","    if(age_group=='45-64' or age_group=='65+'):\n","      return '45+'\n","\n","  # to 2 bins : -45, 45+\n","  def bin2(age_group):\n","    if(age_group=='18-24' or age_group=='<18' or age_group=='25-44'):\n","      return '-45'\n","    if(age_group=='45-64' or age_group=='65+'):\n","      return '45+'\n","\n","  if(bins == 3):\n","    df['age_group'] = df.apply(lambda x: bin3(x['age_group']), axis = 1)\n","  if(bins == 2):\n","    df['age_group'] = df.apply(lambda x: bin2(x['age_group']), axis = 1)\n","  return df\n","\n","# to fill na of some columns\n","def col_fillna(df):\n","  # fill travel_with na with 'Alone'\n","  df['travel_with'].fillna('Alone', inplace=True)\n","  # fill total_male and total_female na with 1\n","  df['total_male'].fillna(1, inplace=True)\n","  df['total_female'].fillna(1, inplace=True)\n","  # replace 'Widlife Tourism' by 'Wildlife Tourism' in main_activity\n","  df = df.replace('Widlife Tourism', 'Wildlife Tourism')\n","  df = df.replace('Yes', 1)\n","  df = df.replace('No', 0)\n","  return df\n","\n","# drop all rows with tour_arrangement=='independent' and any_package=='yes'\n","def clean_tour_arrangment_package(df):\n","  # get concerning rows\n","  df_drop = df.query(\"tour_arrangement=='Independent' and (package_transport_int=='Yes' or package_transport_int=='Yes' or package_accomodation=='Yes' or package_food=='Yes' or package_transport_tz=='Yes' or package_sightseeing=='Yes' or package_guided_tour=='Yes' or package_insurance=='Yes')\")\n","  # remove rows (its 142 at all concerning)\n","  df.drop(df_drop.index, inplace=True)\n","  return df\n","\n","# add package_acc_food (ie. if the tour package include both accomadation and food )\n","def add_package_acc_food(df):\n","  def acc_food(accomodation, food):\n","    if(accomodation==1 and food==1):\n","      return 1\n","    else:\n","      return 0\n","  df['package_acc_food'] = df.apply(lambda x: acc_food(x['package_accomodation'], x['package_food']), axis = 1)\n","  return df\n","\n","# add package_transport (ie. if the tour package include both international and Tanzania transport )\n","def add_package_transport(df):\n","  def transport(international, tz):\n","    if(international==1 and tz==1):\n","      return 1\n","    else:\n","      return 0\n","  df['package_transport'] = df.apply(lambda x: transport(x['package_transport_int'], x['package_transport_tz']), axis = 1)\n","  return df\n","\n","# add package_sight_guided (ie. if the tour package include both sightseeing and guided_tour )\n","def add_package_sight_guided(df):\n","  def sight_guided(sight, guided):\n","    if(sight==1 and guided==1):\n","      return 1\n","    else:\n","      return 0\n","  df['package_sight_guided'] = df.apply(lambda x: sight_guided(x['package_sightseeing'], x['package_guided_tour']), axis = 1)\n","  return df\n","\n","# add package (ie. if the tour package include all package)\n","def add_package(df):\n","  def package(accomodation, food, international, tz, sight, guided):\n","    if(accomodation==1 and food==1 and international==1 and tz==1 and sight==1 and guided==1):\n","      return 1\n","    else:\n","      return 0\n","  df['package'] = df.apply(lambda x: package(x['package_accomodation'], x['package_food'],\n","                                             x['package_transport_int'], x['package_transport_tz'],\n","                                             x['package_sightseeing'], x['package_guided_tour']), axis = 1)\n","  return df\n","\n","# to add total_persons\n","def add_total_persons(df):\n","  df['total_persons'] = df['total_male']+df['total_female']\n","  return df\n","\n","def encode_cat(X, y, encoders, train=True):\n","  # Fit encoder and transform the features\n","  if(train):\n","    for col in X.columns:\n","      if(X[col].dtype == 'O'):\n","        encoders[col].fit(X, y)\n","  for col in X.columns:\n","    if(X[col].dtype == 'O'):\n","      X[col] = encoders[col].transform(X)\n","  \n","  return X, encoders\n","\n","def preprocess_df(df):\n","  #df = clean_tour_arrangment_package(df)\n","  df = country_to_continent(df)\n","  df = binning_age_group(df, bins=3)\n","  df = col_fillna(df)\n","  #df = add_package_acc_food(df)\n","  #df = add_package_transport(df)\n","  #df = add_package_sight_guided(df)\n","  df = add_total_persons(df)\n","\n","  return df"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":409,"status":"ok","timestamp":1664186100482,"user":{"displayName":"Nya Fredy Yann NDINGUE","userId":"12675892843960354959"},"user_tz":-120},"id":"Iwc3mp95awxy"},"outputs":[],"source":["from sklearn.metrics import roc_auc_score as auc\n","from sklearn.linear_model import LogisticRegression\n","\n","# to test both MEE and CatBoost for categorical enconding, with simple logistic regression model\n","# in order to find the best encoding\n","'''\n","conclusion : catboost seems to be better than mean estimate encoder\n","'''\n","train_cp = train.copy()\n","train_proc = preprocess_df(train_cp)\n","y = train_proc['cost_category']\n","y = y.map(lambda x: 0 if x=='Lower Cost' else 1 if x=='Low Cost' else 2 if x=='Normal Cost' else 3 if x=='High Cost' else 4 if x=='Higher Cost' else 5)\n","X = train_proc.copy()\n","drop_cols = ['Tour_ID', 'country', 'cost_category']\n","X.drop(drop_cols, axis=1, inplace=True)\n","\n","xtrain, xvalid, ytrain, yvalid = train_test_split(\n","    X,\n","    y,\n","    test_size = 0.2,\n","    random_state = 42,\n","    shuffle = True,\n","    stratify = y.values    \n",")\n","\n","mee_encoder = ce.MEstimateEncoder(m=10.0)\n","cbe_encoder = ce.cat_boost.CatBoostEncoder()\n","encoders = [mee_encoder, cbe_encoder]\n","\n","for encoder in encoders:\n","  print(encoder)\n","  xtrain_enc, enc = encode_cat(xtrain, ytrain, encoder, train=True)\n","  xvalid_enc, enc = encode_cat(xvalid, yvalid, enc, train=False)\n","  \n","  lr = LogisticRegression(max_iter=1000)\n","  lr.fit(xtrain_enc, ytrain)\n","  train_preds = lr.predict(xtrain_enc)\n","  valid_preds = lr.predict(xvalid_enc)\n","  print('MSE: train, valid', mean_squared_error(ytrain, train_preds, squared=False), mean_squared_error(yvalid, valid_preds, squared=False))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":88652,"status":"ok","timestamp":1663874471757,"user":{"displayName":"Nya Fredy Yann NDINGUE","userId":"12675892843960354959"},"user_tz":-120},"id":"G5UhhFdtoZiF","outputId":"a3f1ae5b-d682-4e63-ca6c-1ebc9209f945"},"outputs":[{"output_type":"stream","name":"stdout","text":["115\n","MSE 0.938794856712211\n","log_loss 0.9638221557029167\n"]}],"source":["# Grid search : find optimal parameters\n","\n","import category_encoders as ce\n","\n","# load files\n","train = pd.read_csv('/content/drive/MyDrive/Zindi/ai4d-lab-tanzania-tourism-classification-challenge/Train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/Zindi/ai4d-lab-tanzania-tourism-classification-challenge/Test.csv')\n","variableDefinitions = pd.read_csv('/content/drive/MyDrive/Zindi/ai4d-lab-tanzania-tourism-classification-challenge/VariableDefinitions.csv')\n","sampleSubmission = pd.read_csv('/content/drive/MyDrive/Zindi/ai4d-lab-tanzania-tourism-classification-challenge/SampleSubmission.csv')\n","train = train.fillna(-1)\n","test = test.fillna(-1)\n","train = country_to_continent(train)\n","train = add_total_persons(train)\n","train = add_package_acc_food(train)\n","train = add_package_transport(train)\n","train = add_package_sight_guided(train)\n","test = country_to_continent(test)\n","test = add_total_persons(test)\n","test = add_package_acc_food(test)\n","test = add_package_transport(test)\n","test = add_package_sight_guided(test)\n","\n","def modelfit(alg, dtrain, target,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n","    \n","    if useTrainCV:\n","        xgb_param = alg.get_xgb_params()\n","        xgtrain = xgb.DMatrix(dtrain.values, label=target.values)\n","        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n","            metrics='mlogloss', early_stopping_rounds=early_stopping_rounds)\n","        alg.set_params(n_estimators=cvresult.shape[0])\n","        print(cvresult.shape[0])\n","    \n","    #Fit the algorithm on the data\n","    alg.fit(dtrain, target,eval_metric='logloss')\n","        \n","    #Predict training set:\n","    dtrain_predictions = alg.predict(dtrain)\n","    dtrain_predprob = alg.predict(dtrain)\n","    print('MSE', mean_squared_error(target, dtrain_predictions.argmax(axis=1), squared=False))\n","    print('log_loss', log_loss(target, dtrain_predictions))\n","\n","# scorer for gridsearch score\n","def log_loss_scorer(clf, X, y):\n","  y_pred = clf.predict(X)\n","  return -1 * log_loss(y, y_pred) # on multiplie par -1 pour que la fonction renvoie la plus petite erreur lorsqu'elle est applelee dans le grid_search (grid search calcule les params avec le score le plus eleve)\n","\n","# train ds\n","train_enc = train.copy()\n","target_col = 'cost_category'\n","train_enc[target_col] = train_enc[target_col].map(lambda x: 0 if x=='Lower Cost' else 1 if x=='Low Cost' else 2 if x=='Normal Cost' else 3 if x=='High Cost' else 4 if x=='Higher Cost' else 5)\n","target = train_enc[target_col]\n","train_enc.drop(['Tour_ID'], axis=1, inplace=True)\n","train_enc.drop('cost_category', axis=1, inplace=True)\n","\n","train_enc_final = train_enc.copy()\n","\n","# test ds\n","test_enc = test.drop(columns=['Tour_ID'])\n","  \n","dict_enc = {col:ce.MEstimateEncoder(m=10.0) for col in train_enc_final.columns} \n","\n","for col in train_enc_final.columns:\n","  if train_enc_final[col].dtype == 'O' :\n","    train_enc_final[col] = dict_enc[col].fit_transform(train_enc_final[col], target)\n","\n","# step 1 : find the best n_estimators value --- found = 119\n","'''\n","model = XGBRegressor(random_state=42, seed=27, objective='multi:softprob', num_class=6, subsample=0.8,\n","                     max_depth=5, min_child_weight = 1, gamma = 0., colsample_bytree = 0.8,  nthread=4, \n","                     scale_pos_weight = 1, reg_alpha=0., learning_rate=0.11, n_estimators=1000)\n","modelfit(model, train_enc_final, target)\n","'''\n","\n","# step 2.a: Tune max_depth and min_child_weight\n","# result: {'max_depth': 5, 'min_child_weight': 5} - time: 13 min 5s\n","'''\n","param_test1 = {\n"," 'max_depth':range(3,10,2),\n"," 'min_child_weight':range(1,6,2)\n","}\n","gsearch1 = GridSearchCV(XGBRegressor(random_state=42, seed=27, objective='multi:softprob', num_class=6, subsample=0.8,\n","                     max_depth=5, min_child_weight = 1, gamma = 0., colsample_bytree = 0.8,  nthread=4, \n","                     scale_pos_weight = 1, reg_alpha=0., learning_rate=0.11, n_estimators=119), \n"," param_grid = param_test1, scoring=log_loss_scorer,n_jobs=4, cv=5, error_score='raise')\n","gsearch1.fit(train_enc_final, target)\n","gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_\n","'''\n","\n","# step 2.b:  we have get max_depth=5, min_child=5 from previous research. let us try with range [4,5,6] to get best \n","# 'max_depth': 5, 'min_child_weight': 6\n","'''\n","param_test2 = {\n"," 'max_depth':[4,5,6],\n"," 'min_child_weight':[4,5,6]\n","}\n","gsearch1 = GridSearchCV(XGBRegressor(random_state=42, seed=27, objective='multi:softprob', num_class=6, subsample=0.8,\n","                     max_depth=5, min_child_weight = 2, gamma = 0., colsample_bytree = 0.8,  nthread=4, \n","                     scale_pos_weight = 1, reg_alpha=0., learning_rate=0.11, n_estimators=119), \n"," param_grid = param_test2, scoring=log_loss_scorer,n_jobs=4, cv=5, error_score='raise')\n","gsearch1.fit(train_enc_final, target)\n","gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_\n","'''\n","\n","# step 2.c: we get 6 as best min_child_weight. we have not tested vlaues greater than 6. \n","#min_child_weight : 10\n","'''\n","param_test2c = {\n"," #'min_child_weight':[6,8,10,12]\n"," 'min_child_weight':[9,10,11]\n","}\n","gsearch1 = GridSearchCV(XGBRegressor(random_state=42, seed=27, objective='multi:softprob', num_class=6, subsample=0.8,\n","                     max_depth=5, min_child_weight = 2, gamma = 0., colsample_bytree = 0.8,  nthread=4, \n","                     scale_pos_weight = 1, reg_alpha=0., learning_rate=0.11, n_estimators=119), \n"," param_grid = param_test2c, scoring=log_loss_scorer,n_jobs=4, cv=5, error_score='raise')\n","gsearch1.fit(train_enc_final, target)\n","modelfit(gsearch1.best_estimator_, train_enc_final, target)\n","gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_\n","'''\n","\n","# step3: tune gamma\n","# 'gamma': 0.1\n","'''\n","param_test3 = {\n"," 'gamma':[i/10.0 for i in range(0,5)]\n","}\n","gsearch3 = GridSearchCV(XGBRegressor(random_state=42, seed=27, objective='multi:softprob', num_class=6, subsample=0.8,\n","                     max_depth=5, min_child_weight = 10, gamma = 0., colsample_bytree = 0.8,  nthread=4, \n","                     scale_pos_weight = 1, reg_alpha=0., learning_rate=0.11, n_estimators=119), \n"," param_grid = param_test3, scoring=log_loss_scorer,n_jobs=4, cv=5, error_score='raise')\n","gsearch3.fit(train_enc_final, target)\n","modelfit(gsearch3.best_estimator_, train_enc_final, target)\n","gsearch3.cv_results_, gsearch3.best_params_, gsearch3.best_score_\n","'''\n","# recalibrate n_estimators\n","#n_estimators = 144\n","'''\n","model = XGBRegressor(random_state=42, seed=27, objective='multi:softprob', num_class=6, subsample=0.8,\n","                     max_depth=5, min_child_weight = 10, gamma = 0.1, colsample_bytree = 0.8,  nthread=4, \n","                     scale_pos_weight = 1, reg_alpha=0., learning_rate=0.11, n_estimators=1000)\n","modelfit(model, train_enc_final, target)\n","'''\n","\n","# step 4 : tune col_sample_bytree and subsample\n","# 'colsample_bytree': 0.6, 'subsample': 0.6\n","'''\n","param_test4 = {\n"," 'subsample':[i/10.0 for i in range(6,10)],\n"," 'colsample_bytree':[i/10.0 for i in range(6,10)]\n","}\n","gsearch4 = GridSearchCV(XGBRegressor(random_state=42, seed=27, objective='multi:softprob', num_class=6, subsample=0.8,\n","                     max_depth=5, min_child_weight = 10, gamma = 0.1, colsample_bytree = 0.8,  nthread=4, \n","                     scale_pos_weight = 1, reg_alpha=0., learning_rate=0.11, n_estimators=144), \n"," param_grid = param_test4, scoring=log_loss_scorer,n_jobs=4, cv=5, error_score='raise')\n","gsearch4.fit(train_enc_final, target)\n","modelfit(gsearch4.best_estimator_, train_enc_final, target)\n","gsearch4.cv_results_, gsearch4.best_params_, gsearch4.best_score_\n","'''\n","# 'colsample_bytree': 0.6, 'subsample': 0.65\n","'''\n","param_test4 = {\n"," 'subsample':[i/100.0 for i in range(55,70,5)],\n"," 'colsample_bytree':[i/100.0 for i in range(55,70,5)]\n","}\n","gsearch4 = GridSearchCV(XGBRegressor(random_state=42, seed=27, objective='multi:softprob', num_class=6, subsample=0.6,\n","                     max_depth=5, min_child_weight = 10, gamma = 0.1, colsample_bytree = 0.6,  nthread=4, \n","                     scale_pos_weight = 1, reg_alpha=0., learning_rate=0.11, n_estimators=144), \n"," param_grid = param_test4, scoring=log_loss_scorer,n_jobs=4, cv=5, error_score='raise')\n","gsearch4.fit(train_enc_final, target)\n","gsearch4.cv_results_, gsearch4.best_params_, gsearch4.best_score_\n","'''\n","\n","'''\n","param_test5 = {\n"," 'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n","}\n","gsearch5 = GridSearchCV(XGBRegressor(random_state=42, seed=27, objective='multi:softprob', num_class=6, subsample=0.65,\n","                     max_depth=5, min_child_weight = 10, gamma = 0.1, colsample_bytree = 0.6,  nthread=4, \n","                     scale_pos_weight = 1, reg_alpha=0.01, learning_rate=0.11, n_estimators=144), \n"," param_grid = param_test5, scoring=log_loss_scorer,n_jobs=4, cv=5, error_score='raise')\n","gsearch5.fit(train_enc_final, target)\n","gsearch5.cv_results_, gsearch5.best_params_, gsearch5.best_score_\n","'''\n","\n","# recalibrate n_estimators\n","#n_estimators = 115, log_loss=0.9638\n","model = XGBRegressor(random_state=42, seed=27, objective='multi:softprob', num_class=6, subsample=0.65,\n","                     max_depth=5, min_child_weight = 10, gamma = 0.1, colsample_bytree = 0.6,  nthread=4, \n","                     scale_pos_weight = 1, reg_alpha=0.01, learning_rate=0.11, n_estimators=1000)\n","modelfit(model, train_enc_final, target)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8717,"status":"ok","timestamp":1664185864246,"user":{"displayName":"Nya Fredy Yann NDINGUE","userId":"12675892843960354959"},"user_tz":-120},"id":"9N0hTHmXvjFS","outputId":"6713ce85-33c5-4dc2-b6f8-55f4fcf91a1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["train\n","MSE 0.9377645844059436\n","log_loss 0.9590592325025031\n","valid\n","MSE 0.9503146756253603\n","log_loss 1.0440353382773353\n"]}],"source":["# solution\n","'''\n","- target encoding : normal 2 - higher 4 - high 3 - lower 0 - low 1 - highest 5\n","- categorical encoding: MestimateEncoder\n","- predictors : xgboost with optimal params (grid search have been done before) \n","'''\n","import category_encoders as ce\n","\n","# load files\n","train = pd.read_csv('/content/drive/MyDrive/Zindi/ai4d-lab-tanzania-tourism-classification-challenge/Train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/Zindi/ai4d-lab-tanzania-tourism-classification-challenge/Test.csv')\n","variableDefinitions = pd.read_csv('/content/drive/MyDrive/Zindi/ai4d-lab-tanzania-tourism-classification-challenge/VariableDefinitions.csv')\n","sampleSubmission = pd.read_csv('/content/drive/MyDrive/Zindi/ai4d-lab-tanzania-tourism-classification-challenge/SampleSubmission.csv')\n","train = train.fillna(-1)\n","test = test.fillna(-1)\n","train = country_to_continent(train)\n","train = add_total_persons(train)\n","train = add_package_acc_food(train)\n","train = add_package_transport(train)\n","train = add_package_sight_guided(train)\n","test = country_to_continent(test)\n","test = add_total_persons(test)\n","test = add_package_acc_food(test)\n","test = add_package_transport(test)\n","test = add_package_sight_guided(test)\n","\n","\n","#train = binning_age_group(train, bins=3)\n","#train = col_fillna(train)\n","#test = col_fillna(test)\n","\n","# train ds\n","train_enc = train\n","\n","encoding_dict = dict()\n","col = 'cost_category'\n","value = train_enc[col].value_counts().index.tolist()\n","dict_value = {value:count for value,count in zip(value, range(1, len(value)+1))}\n","encoding_dict[col] = dict_value\n","#train_enc[col] = train_enc[col].map(lambda x: dict_value.get(x)) - 1\n","train_enc[col] = train_enc[col].map(lambda x: 0 if x=='Lower Cost' else 1 if x=='Low Cost' else 2 if x=='Normal Cost' else 3 if x=='High Cost' else 4 if x=='Higher Cost' else 5)\n","\n","dict_enc = {col:ce.MEstimateEncoder(m=10.0) for col in train_enc.columns}\n","#dict_enc = {col:ce.cat_boost.CatBoostEncoder() for col in train_enc.columns}\n","\n","for col in train_enc.columns:\n","  if train_enc[col].dtype == 'O' :\n","    train_enc[col] = dict_enc[col].fit_transform(train_enc[col], train_enc['cost_category'])\n","train_enc_final = train_enc.copy()\n","train_enc_final.drop(['Tour_ID'], axis=1, inplace=True)\n","train_enc_final.drop('cost_category', axis=1, inplace=True)\n","\n","# test ds\n","test_enc = test.drop(columns=['Tour_ID'])\n","for col in test_enc.columns:\n","  if test_enc[col].dtype == 'O':\n","    test_enc[col] = dict_enc[col].transform(test_enc[col])\n","test_enc_final = test_enc\n","\n","xtrain, xvalid, ytrain, yvalid = train_test_split(\n","    train_enc_final,\n","    train_enc['cost_category'],\n","    test_size = 0.15,\n","    random_state = 42,\n","    shuffle = True,\n","    stratify = train['cost_category'].values    \n",")\n","\n","xtest = test_enc_final\n","\n","model = XGBRegressor(seed=27, objective='multi:softprob', eta=0.005, num_class=6, subsample=0.65,\n","                     max_depth=5, min_child_weight = 10, gamma = 0.1, colsample_bytree = 0.6,  nthread=4, \n","                     scale_pos_weight = 1, reg_alpha=0.01, learning_rate=0.11, n_estimators=115)\n","\n","model.fit(xtrain, ytrain)\n","train_preds = model.predict(xtrain)\n","valid_preds = model.predict(xvalid)\n","test_preds = model.predict(xtest)\n","print(\"train\")\n","print('MSE', mean_squared_error(ytrain, train_preds.argmax(axis=1), squared=False))\n","print('log_loss', log_loss(ytrain, train_preds))\n","print(\"valid\")\n","print('MSE', mean_squared_error(yvalid, valid_preds.argmax(axis=1), squared=False))\n","print('log_loss', log_loss(yvalid, valid_preds))\n","\n","preds0 = test_preds[:, 0]\n","preds1 = test_preds[:, 1]\n","preds2 = test_preds[:, 2]\n","preds3 = test_preds[:, 3]\n","preds4 = test_preds[:, 4]\n","preds5 = test_preds[:, 5]\n","\n","sampleSubmission['Normal Cost'] = preds2\n","sampleSubmission['Higher Cost'] = preds4\n","sampleSubmission['High Cost'] = preds3\n","sampleSubmission['Lower Cost'] = preds0\n","sampleSubmission['Low Cost'] = preds1\n","sampleSubmission['Highest Cost'] = preds5\n","sampleSubmission.to_csv('/content/drive/MyDrive/Zindi/ai4d-lab-tanzania-tourism-classification-challenge/sub_final3.csv', index = False)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyOdd9WAWAwZT2LyeOVPxVZ6"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}